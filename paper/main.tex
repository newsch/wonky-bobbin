\documentclass{article}\twocolumn
\usepackage{./paper}

\graphicspath{ {../figures/} }

\title{Digital Camera Image Processing Pipeline Components}
\author{Hadleigh Nunes and Evan Lloyd New-Schmidt}
\date{Fall 2018}

\begin{document}

\maketitle


\begin{abstract}
    In this paper we explore concepts and methods for processing digital images in the initial stages of image development, including demosaicing, gamma correction, and white balance correction.
\end{abstract}

\section{Introduction}


% TODO: fig: overview of pipeline components

\begin{figure}[!h]
    \centering
    \includegraphics[width=\columnwidth]{bggr_bayer_pattern}
    \caption{Example of the BGGR Bayer grid used by the Raspberry Pi camera. Included from the \lstinline{picamera} module documentation\cite{picameradocs}.}
    \label{fig:bayer_pattern}
\end{figure}

% TODO: fig: bayer images comparison ala wikipedia

% TODO: fig: gamma curves
% TODO: fig: gamma correction image comparison

% TODO: fig: white balance comparison
\begin{figure}[!h]
    \centering
    \includegraphics[width=\columnwidth]{edge_zippering.pdf}
    \caption{Example of zippering effect from demosaicing with bilinear interpolation.}
    \label{fig:edge_zippering}
\end{figure}

\section{Mathematical Background}
The mathematical procedures we use are based mainly in Linear Algebra, Multivariable Calculus and Signal Processing. The simplest method of debayering is nearest neighbor interpolation, which we implemented by convolving a  $3x3$ kernel with each of the color channels. In the raw image, the matrix of each color channel contains values only in pixels corresponding to a sencel of the corresponding color. Pixel locations corresponding to a different color channel are occupied by zeros. By convolving the matrix 
    \begin{align}
        \threebythree{1}{1}{1}{1}{1}{1}{1}{1}{1}
    \end{align}
with each channel we are essentially averaging the adjacent pixel values of each pixel, including those diagonally adjacent. This is a rudimentary technique, and will create some artifacts, one of the more prominent being a 'zippering' effect caused by %TODO: details on zippering
There are many more complex approaches to debayering designed to reduce the artifacts created in the process. The first widely used such approach is the Kimmel algorithm\cite{kimmel_demosaicing:_1999}, which models the image as a piece-wise three dimensional surface, and interpolates in the direction orthogonal to the gradient, along the gentlest slope. The algorithm assumes that the ratio of red, green and blue values remains constant locally within continuous function elements; that is hue changes smoothly within the edges of a given element. The Kimmel algorithm approximates directional derivatives at every unknown pixel point, and assigns weights to each neighboring pixel inversely proportional to the magnitude of that derivative. The sum of the products of these pixels and their weights becomes the new interpolated value of the target point. 


\section{Quantitative Procedure}

\subsection{Debayering}

    
    
\subsection{Gamma Correction}
    Raw digital images are often hard to interpret, as even when scaled to a full RGB range, the non-white parts of the image appear dark with little contrast. This effect occurs because the human eye perceives light non-linearly, meaning that though there may be a significant linear numerical variance in darker regions of an image, those differences are hard to interpret visually. To correct for this, the pixel values of a digital image are adjusted according to a power function. 
    \begin{equation}
        V_{out} = AV_{in}^{\gamma} \label{eqn:Gamma}
    \end{equation}
    The expression \eqref{eqn:Gamma} is the general form of the gamma function, where $A$ is a constant scalar, $V_{in}$ and $V_{out}$ are the input and output signals, respectively. 
    Typically for a "decoding" $\gamma$, a $\gamma$ function meant to re-scale a digital image for human viewing, a $\gamma < 1$ is used to enhance the visibility of non-white areas. 
\subsection{Sharpening}
    We use another convolution process to sharpen images. The kernel 
    \begin{align}
        \threebythree{0}{-1}{0}{-1}{5}{-1}{0}{-1}{0}
    \end{align}
when convolved with an image produces a sharpened image, as color values which are highly present in neighboring pixels are reduced if not as present in the target pixel. This kernel works well for relatively low resolution images, but when applied to images with higher pixel density, the results are minimal. 

\subsubsection{Peak Signal-to-Noise Ratio (PSNR)}

Once we reconstruct the image using a demosaicing method, we compare it with the original image using Peak Signal-to-Noise Ratio (PSNR). This technique is used in several other papers to validate demosaicing techniques (\cite{zapryanov_comparative_2008}, \cite{lukin_high-quality_2004}, and \cite{kimmel_demosaicing:_1999}).

Given two color images, an input image $I$ and a reconstructed image $K$, of size $m$ x $n$ represented in RGB, the mean squared error ($MSE$) is calculated as

\begin{equation}
    \textit{MSE} = \frac{1}{3mn} \sum^{m-1}_{i=0} \sum^{n-1}_{j=0} \sum^{2}_{k=0} [I(i, j, k) - K(i, j, k)]^2
\end{equation}

and the PSNR is calculated as

\begin{equation}
    \textit{PSNR} = 10 \log_{10}{\frac{\textit{MAX}^2_I}{\textit{MSE}}}
\end{equation}

where $\textit{MAX}_I$ is the largest possible pixel value for the image. For the purposes of this paper we use 8-bit images, so $\textit{MAX}_I = 2^8 - 1 = 255$.

%\subsection{White Balance}

\subsection{Further Applications}


\section{Results and discussion}

% TODO: fig: PSNR results w/ linear interpolation and Kimmel

\section{Conclusion}


\section{Equations} 
\begin{equation}
    I^{R} = \rho _{R}(X)<\hat{\mathbf{N}}(x),\vec{l}>
    I^{G} = \rho _{G}(X)<\hat{\mathbf{N}}(x),\vec{l}>
\end{equation}
$\vec{l}$ is the light source direction, $\hat{\mathbf{N}}(x)$ is the normal vector to the surface at a pixel point
\begin{equation}
    I^{R} = \rho _{R}(X)<\hat{\mathbf{N}}(x),\vec{l}> \label{eqn:surface}
    I^{G} = \rho _{G}(X)<\hat{\mathbf{N}}(x),\vec{l}>
\end{equation}
where $\vec{l}$ is the light source direction, $\hat{\mathbf{N}}(x)$ is the normal vector to the surface at a pixel.
\begin{equation}
    \tilde{\mathbf{I}}(x) = <\hat{\mathbf{N}}(x),\vec{l}>
\end{equation}

\begin{equation}
    \frac{\mathbf{I^{i}}}{\mathbf{I^{j}}} = \frac{\rho _{i}(X)\tilde{\mathbf{I}}(x)}{\rho _{j}(X)\tilde{\mathbf{I}}(x)} = \frac{c_{i}}{c_{j}} = constant
\end{equation}

\begin{equation}
    cov = (\textbf{X} - \mu_{x})(\textbf{X} - \mu_{x})^{T}
\end{equation}

\begin{equation}
    \textbf{M} = \textbf{U} \textbf{$\Sigma$} \textbf{V}
\end{equation}

\begin{equation}
    \textbf{U} = (\textbf{X} - \mu_{x}) \textbf{V} \Sigma^{-1}
\end{equation}

\begin{equation}
    \textbf{W} = \textbf{U}_{Basis}^{T} \textbf{Im}
\end{equation}

% REFERENCES
% References are listed in BibTeX format in the `references.bib` file.
% You can use http://www.citationmachine.net/bibtex/ to create citations in that format.
% Google Scholar will also output BibTeX - click on the quotes to cite and then select "BibTeX".
% Zotero: right-click -> export... -> bibtex format
% entries will only show up if they are used with \cite

\bibliographystyle{IEEEtran}
\bibliography{IEEEabrv,references.bib}

\end{document}