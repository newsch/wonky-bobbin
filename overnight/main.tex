\documentclass{tufte-handout}
\usepackage{./fall2018_preamble_v1.0}

\IfSubStr{\jobname}{\detokenize{Solutions}}{\toggletrue{solutions}}{\togglefalse{solutions}}

\fancypagestyle{firstpage}

{\rhead{How Can Images Be Real If Our Cameras Aren't Real? \linebreak \textit{Version: \today} \linebreak \href{https://github.com/newsch/wonky-bobbin/blob/master/overnight/main.tex}{source}}}

\title{Overnight Overnight: How Can Images Be Real If Our Cameras Aren't Real?}
\author{QEA}
\date{Fall 2018}

\toggletrue{solutions}
% \togglefalse{solutions}

\begin{document}

\maketitle
\thispagestyle{firstpage}

% % in the first problem block, make sure to use the series option for enumerate
% \begin{enumerate}[series=exercises, label=\textbf{Exercise} (\arabic*)]
% \item The text of the first exercise
% \solution{Here is the solution.}
% \end{enumerate}
% % when adding a second block of problems make sure to use "resume" instead of "series"
% \begin{enumerate}[resume=exercises, label=\textbf{Exercise} (\arabic*)]
% \item The text of the second exercise.
% \iftoggleverb{solutions}
% \textbf{Solution:}
% \begin{lstlisting}
% x = linspace(0, 2*pi, 100);
% y = 5;
% \end{lstlisting}
% \fi
% \end{enumerate}

\section{Overview}

The goal of this assignment is to get familiar with the concepts of digital image processing and the mathematical concepts involved with them. In this assignment you'll implement some common photo manipulation methods and learn some concepts that will prepare you for further work in this area.

\section{Learning Goals}

\begin{itemize}
\item Understand the relationship between the physical equipment used to capture
images and the digital representation of them, including:
    \begin{itemize}
        \item CCDs and Bayer grids
        \item Linear vs Nonlinear space and Gamma correction
        \item White Balance adjustment
    \end{itemize}
\item Understand how data is stored in bits/bytes and how that impacts various
operations and manipulations
% \item Feel comfortable working with matrix operations in Python and Jupyter notebooks
\item Be able to implement basic linear interpolation debayering in Python
\item Become comfortable with concepts needed for more advanced algorithms.
\item Re-familiarize with PCA and Eigenspaces.
\end{itemize}

\section{Image manipulation}

\subsection{Review of Image Manipulation (now in Python) [1 hr]}

Re-familiarize yourself with some of the image manipulation we did in the faces module, specifically the brightness and contrast section (problems 9-14) of \href{https://drive.google.com/file/d/0B7LNBbaxYFujOHpEU2FDdkF6VEE/view
}{Module 2, Night 3}.

\begin{enumerate}[series=exercises, label=\textbf{Exercise} (\arabic*)]
    \item Implement problems 9-14 in Python, using numpy operations.
\end{enumerate}

\subsection{2D Convolution w/ Kernels [2 hrs]}

You already were introduced to the concept of convolution in \href{https://drive.google.com/file/d/1_eEtwNDHhF-Izfcf6l00PvG-b6whwety/view}{FitBit Night 2}. In this overnight assignment we're going to use it with discrete 2-dimensional signals: images!

We'll do this by convolving the fairly complex and discrete matrix of an image with a much smaller and simpler matrix commonly called a kernel. This kernel can be used to quickly perform algebraic operations on the pixels of an image relative to their neighbors.

Take the discrete convolution of these two 3x3 matrices for example:
\begin{align}
    \threebythree{0}{0}{0}{0}{2}{0}{0}{0}{0} * \threebythree{1}{1}{1}{1}{1}{1}{1}{1}{1} =
    \threebythree{2}{2}{2}{2}{2}{2}{2}{2}{2}
\end{align}

One way to read think of this (with the left matrix as our "kernel" and the right matrix as our "image") is \emph{"For every element in the image, sum the element multiplied by 2 and each of its neighbors multiplied by 0"}.

In practice, this is equivalent to both of the following operations:
\begin{align}\label{eqn:convolution1}
    \begin{bmatrix}2\end{bmatrix} * \threebythree{1}{1}{1}{1}{1}{1}{1}{1}{1} =
    \threebythree{2}{2}{2}{2}{2}{2}{2}{2}{2}
\end{align}

\begin{align}
    2 \threebythree{1}{1}{1}{1}{1}{1}{1}{1}{1} = \threebythree{2}{2}{2}{2}{2}{2}{2}{2}{2}
\end{align}

To write this generally, the resulting matrix $G$ of the correlation of matrices $H$ (our kernel) and $F$ (our image),
\begin{align}
    H * F = G
\end{align}
is calculated as:
\begin{align}
    G[i, j] = \sum_{u=-k}^{k} \sum_{v=-k}^{k} H[u, v] F[i - u, j - v]
\end{align}
\emph{Note: the actual operation performed here involves flipping the rows and columns of the kernel. All of the examples that we're looking at use symmetric kernels, so you won't need to take that into consideration.}

However, the kernel we used in the initial example is not a particularly exciting one. As you saw, it's actually equivalent to an element-wise multiplication. The really exciting stuff starts to happen when you use kernels with non-zero surrounding elements.

Let's look at the following example:
\begin{align}\label{eqn:convolution2}
    \threebythree{0}{1}{0}{1}{2}{1}{0}{1}{0} * \threebythree{1}{1}{1}{1}{1}{1}{1}{1}{1} =
    \threebythree{4}{5}{4}{5}{6}{5}{4}{5}{4}
\end{align}
Again, you can read this as \emph{"For every element in the image, sum the element multiplied by 2 with the values of its cardinal neighbors"}.

One thing we haven't talked about yet is how to treat the elements on the edges of the matrix that aren't bordered by 8 other elements. There are several methods that can be used when calculating the convolution, including:
\begin{itemize}
    \item ignoring values in the matrix that aren't completely bordered (this results in a matrix with $n-2$ fewer rows and columns)
    \item "wrapping" the matrix edges around PAC-MAN style
    \item considering all none-present elements equal to 0 (or alternatively, "padding" the matrix borders with zeros)
\end{itemize}
As you may have discerned from the above example \eqref{eqn:convolution2}, we're going to be the using the third method of treating these elements as if they are 0. In the context of image manipulation, we don't want to reduce the size of our images with every operation, and wrapping the image around doesn't really make sense (unless you're working with some sort of 360-degree panorama, where the left/right and top/bottom of the image actually do touch).

\bex
\item Calculate the convolutions of these three kernels:
    \begin{enumerate}
        \item \threebythree{0}{1}{0}{1}{1}{1}{0}{1}{0}
        \item \threebythree{0}{1}{0}{1}{-4}{1}{0}{1}{0}
        \item \threebythree{0}{\frac{1}{5}}{0}{\frac{1}{5}}{\frac{1}{5}}{\frac{1}{5}}{0}{\frac{1}{5}}{0}
    \end{enumerate}
    with these three matrices:
    \begin{enumerate}
        \item \threebythree{0}{1}{0}{0}{1}{0}{0}{1}{0}
        \item \threebythree{1}{2}{1}{2}{3}{2}{1}{2}{1}
        \item \threebythree{5}{4}{3}{4}{3}{2}{3}{2}{1}
    \end{enumerate}
    What do you notice about their effects? How do the results of kernel (a)
    differ from kernels (b) and (c)?
    \solution{Kernels (b) and (c) preserve the amount of "energy"/brightness in the image, while (a) increases it.}  % TODO: math out the convolutions
\item Can you think of an "identity" kernel, that returns the same image?
\solution{\threebythree{0}{0}{0}{0}{1}{0}{0}{0}{0} or similar (could be
different dimensions)}
\eex

\subsection{Data Types, Numpy, and Matplotlib [30 min]}

Before we turn you loose to start working with convolution and images in Python, we're going to give you some tips for working with images as matrices. These mainly revolve around how Python/Numpy store data and how Matplotlib displays matrix data.

First, lets talk about data types. You've probably heard about integers and floats in ModSim. The main difference between them is that integers store, well, integer values (numbers without a fractional component), while floats can represent fractions (or at least estimates of them). Generally Python is pretty good about knowing when to work with integers vs floats and converting between them, but Numpy can be a little more tricky (it introduces its own types, including (but not limited to) \lstinline{np.float32}, \lstinline{np.int16}, and \lstinline{np.uint8}).

The numbers at the ends of those types are the number of bits that they use to store their values. A \emph{bit} (a portmanteau of \emph{binary digit}) can store either 0 or 1 for a value. Together, multiple bits can encode larger values. 8 bits are commonly called a \emph{byte}\footnote{But not always! In the past, \emph{byte} could refer to smaller or larger numbers of bits, depending on the computer. Technically, \emph{octet} the more specific and correct term.} and can represent 256, or $2^8$ different values.

You might have noticed that we listed the \lstinline{np.uint8} type earlier and are asking yourself, \emph{"What does the 'u' mean?"}. In this case, \emph{u} means \emph{unsigned}, in the mathematical sense of +/-. If we want to store a number's sign, we need to use another bit. In most modern computers, it's preferable to use multiples of 8 for data types, so generally the signed variant of an integer loses a bit\footnote{Get it?} of value in order to store the sign. For example, the maximum value of the \lstinline{np.int8} data type is 127, and the minimum value is -128, while the maximum and minimum values of \lstinline{np.uint8} are 255 and 0, respectively. Note that both types can represent 256 different values. The best one to use varies from situation to situation.

Why do we bring this up? Without understanding how the data types you use behave in certain situations, your code may exhibit some very peculiar behavior. One such case to consider about is \emph{integer overflow}. When a numerical data type exceeds its representable range it is known as \emph{overflow}\footnote{You might also come across the term \emph{underflow}, which can (confusingly) refer to either a data type exceeding the lower bound of its representable range, or a case in floating-point arithmetic where the value's precision cannot be properly represented.}. Depending on the language and system, this can cause the value to \emph{saturate} at the limit (\emph{e.g.} \lstinline{255 + 1 = 255} for an unsigned 8-bit integer) or to \emph{wrap} to the other limit (\emph{e.g.} \lstinline{-128 - 1 = 127} for a signed 8-bit integer).

% TODO: fig: wikipedia's odometer physical overflow example

You may be fortunate enough to encounter a warning or error when this case occurs. In other cases you won't have any indication except for funky behavior, and you'll be in a much better place for debugging if you know to check for overflows. At the time of this writing, numpy/scipy do not provide warnings when overflow occurs in convolution operations.

\bex
\item Create a number of type \lstinline{np.int8}. Cause it to overflow. Is this \emph{wrapping} or \emph{saturating} behavior?
\solution{Numpy overflows wrap (\lstinline{np.int8(127) + np.int8(1)} yields \lstinline{-128}).}
\eex

In digital images, pixel values are commonly represented with 8 bits of precision, ranging in value from 0 to 255. Unsigned 8-bit integers are the perfect data type for storing images of this kind, but when working with them (adding, multiplying, \emph{etc.}) you should use a data type that can handle any potential changes in value from the operations. One such type is a signed integer with a higher precision such as \lstinline{np.int32}, but you don't get the benefits of floating-point arithmetic. We'll discuss this more after the break.

\bex
\item What kind of behavior could integer overflow cause when working with images?
\solution{One example: sections of the image that should appear dark could appear light and \emph{vice versa}.}
\eex

% TODO: explain floats

For image manipulation, we recommend using the \lstinline{np.float32} type, which will allow you to use decimal precision and work with images to your heart's content.

An important thing to note is that the \lstinline{matplotlib.pyplot.imshow} function behaves differently for integers and floats. When displaying integer data, \lstinline{imshow} interprets values \emph{less than or equal to 0 as black}, and values \emph{greater than or equal to 255} as completely white/red/green/blue, depending on the context (2D arrays are interpreted as black/white and 3D arrays with a depth of size 3 are interpreted as RGB images). With float data on the other hand, \lstinline{imshow} interprets values \emph{less than or equal to 0.0 as black}, and values \emph{greater than or equal to 1.0} as completely white/red/green/blue.

% TODO: link to scipy documentation

This means that when converting between integer and float types, you'll want to scale between $[0,\ 255]$ and $[0.0,\ 1.0]$. Another function that may be useful is \lstinline{np.clip}, which you can you to lop off values outside of a given range (like $[0,\ 255]$).

% TODO: talk about considerations with astype

\subsection{Convolution for Image Manipulation [1 hr]}

Convolution can be implemented on two-dimensional arrays for a number of applications. Specific kernels can produce desired effects when convolved with digital images. Unlike the matrix-wide scaling we used for brightness and contrast adjustment, convolution allows us to perform operations relative to a pixel's neighbors, like increasing local contrast between pixels for example.

If you'd like more information on how kernels and convolution work with images, I would highly recommend \href{http://setosa.io/ev/image-kernels/}{Explained Visually's interactive page on image kernels}.

\bex
\item Read the \href{https://en.wikipedia.org/wiki/Kernel_(image_processing)}{Wikipedia page on image kernels}.

\item Implement the sharpening kernel in the Wikipedia article above, and try it out on a grayscale image (make sure the image isn't too large, or the results will be hard to see).
\item Implement the edge detection kernel. How does it compare to the kernels you worked with earlier?
\eex

\subsection{Gamma Correction [1 hr]}  % TODO: (Hadleigh)

\href{https://en.wikipedia.org/wiki/Gamma_correction}{link to Wikipedia page on Gamma Correction}
Gamma correction is a technique to remap the pixel values of a digital image according to a logarithmic scale to range more readable to human eyes.
\begin{enumerate}
    \item Use the numpy power function to raise each element in an array to a power between one and 0.
    \item Read the Wikipedia page and try using the value suggested there.
\end{enumerate}

\section{Demosaicing}

% \subsection{Background on Bayer filters}  % TODO: (Evan)

\subsection{Simple Demosaicing w/ Convolution [1 hr]}

% TODO: do grayscale first, then RGB

The most basic method for debayering a digital color image is to simply calculate the average of the neighboring values, a form of \emph{bilinear interpolation}.

\bex
\item Look back at problems 2 and 7 of \href{https://drive.google.com/file/d/1_eEtwNDHhF-Izfcf6l00PvG-b6whwety/view}{FitBit Night 2} to remind yourself of how moving average filters and convolution work.
\item Think through how you could use convolution to compute the components necessary to calculate the averages (for each pixel you'll need the sum of its neighbors of the same color, and the total number of neighbors).
% TODO: provide array of Bayer grid data
\item Implement this form of debayering in Python.
\eex

% note artifacts
% what else is needed?
% - vignetting
% - gamma correction
% - white balance

% \section{Advanced Demosaicing/White Balance foundations}

% \subsection{Prep for other algorithm}  % TODO: decide on another algorithm to discuss

\subsection{PCA denoising algorithm [1 hr]}  % TODO: (Hadleigh)

Local Pixel Grouping and Principal Component Analysis are commonly used in image denoising algorithms. Image noise is mostly spatially independent, meaning that by analyzing the principal components of small groups of pixels, the noise patterns can be determined. \href{https://www4.comp.polyu.edu.hk/~cslzhang/paper/PR_10_x_3.pdf}{Here is a paper detailing a LPG and PCA based denoising algorithm}.

\bex
\item Scan the paper, paying most attention to the procedure needed to implement this process. Write out pseudo-code for the procedure. %TODO: Write and scan pseudocode (Hadleigh)
\eex

\begin{align}
 \mu_{d} = \frac{1}{N} \sum_{i=1}^{N} d_{i} \label{eqn:Mean}
\end{align}

\begin{align}
\Phi = \mathbf{MM}^{T} \label{eqn:Covariance}
\end{align}

\eqref{eqn:Mean} is the equation for the mean value of an image. This value should be subtracted from the matrix of pixel values to mean center the image for co-variance \eqref{eqn:Covariance} and eigen decomposition.

%\begin{figure}
%\includegraphics[width=11cm]{figs/Saddle_point_contour.pdf}
%\caption{Contour plot of $f(\x)$. }
%\label{figSaddlePointContour}
%\end{figure}

%Figure \ref{figSaddlePointSurf}

\end{document}